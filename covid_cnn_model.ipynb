{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmiPRqy3m8Q",
        "colab_type": "text"
      },
      "source": [
        "# DEEP LEARNING WITH COVID-19 XRAY CONVOLUTED NEURAL NETWORK\n",
        "\n",
        "### Tensorflow, Keras, Sci-Kit Learn\n",
        "\n",
        "Mitchell Thomas\n",
        "\n",
        "\n",
        "---\n",
        "##[Disclaimer: Please note that this project is not scientifically tested or prepared for use in any other setting than a personal project.]\n",
        "\n",
        "\n",
        "\n",
        "I decided to take on the project of identifying whether X-ray imagery of lungs contained COVID-19 virus or were healthy. Through doing this I was able to study various types of convolutional neural networks, image classification, and real world example of model analysis and where shortcomings working with real problems.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqRNH1J-_3mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "!pip install tensorflow \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from imutils import paths\n",
        "\n",
        "import argparse\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import keras \n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D\n",
        "from keras import models\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LHcvGUK7Mna",
        "colab_type": "text"
      },
      "source": [
        "**The Data**\n",
        "\n",
        "I would say the largest shortcoming that I foresaw from the start was lack of data and COVID-19 X-ray images. However, I decided to move forward with the project anyways in hopes of larger datasets in the future that I can tune this network to.\n",
        "\n",
        "I found a great resource online that had compiled a dataset of 25 Posterieranterior COVID-19 infected lung x-rays and 25 x-rays of healthy lungs to feed into my neural network ultimately. Please refer [to this helpful post from pyimagesearch.com](https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/) for more details.\n",
        "\n",
        "The csv file comes from a Kaggle dataset that I found with the same COVID-19 infected lung x-rays as the author of the above pyimagesearch post used to compile the data.\n",
        "\n",
        "Find the kaggle dataset here --> https://www.kaggle.com/bachrr/covid-chest-xray#metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPqMk6xhGRea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('metadata.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HRq_CsU8kID",
        "colab_type": "text"
      },
      "source": [
        "## **Let's Get To It**\n",
        "\n",
        "After importing the dataset, below I have matched up all of the healthy/covid images with their corresponding labels using the package cv2.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I then go on to establish parameters (which I had tuned throughout the project to find optimum results). These parameters are number of epochs (or times passing through CNN), learning rate (which is how drastically the weights are affected as the network learns), and batch size (which is number of training samples used in one iteration).\n",
        "\n",
        "\n",
        "\n",
        "## **Feature and Label Vectors**\n",
        "\n",
        "I then initialize my feature and label vectors. My feature vectors consist of the attributes that are being used to determine the outcome, or prediction of the network, which is the label vector.\n",
        "\n",
        "As I built these initial vectors, I resized the x-ray images to be 224x224 pixels so that they were standardized and uniform.\n",
        "\n",
        "## **One-Hot Encoding the label vector data**\n",
        "\n",
        "In order to work with the classes covid/healthy in a way that they were numerical, but not ordinal, I used one-hot encoding, which basically creates more attributes, or dimensions, your dataset is working with by number of unique labels and either fills them with a value of 1 or 0 based on whether that entry is associated with the corresponding label. Here I used LabelBinarizer() as I had two classes. (Binary)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Last but not least, I shuffled both vectors just for safe keeping to make sure that they were all jumbled up and my training data had a variety to train on and test on, or as much as possible with 50 total datapoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8SbfskfGR8T",
        "colab_type": "code",
        "outputId": "da90bccc-bc06-4174-882e-1fef3e1854ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "covid_data = []\n",
        "normal_data = []\n",
        "covid_imgs = glob.glob (\"/content/datasets/covid/*\")\n",
        "normal_imgs = glob.glob(\"/content/datasets/healthy/*\")\n",
        "\n",
        "for myFile in covid_imgs:\n",
        "    # print(myFile)\n",
        "    image = cv2.imread(myFile)\n",
        "    covid_data.append(image)\n",
        "\n",
        "print('covid_data shape:', np.array(covid_data).shape)\n",
        "\n",
        "for myFile in normal_imgs:\n",
        "    # print(myFile)\n",
        "    image = cv2.imread(myFile)\n",
        "    normal_data.append(image)\n",
        "\n",
        "print('normal_data shape:', np.array(normal_data).shape)\n",
        "\n",
        "# initial model parameters\n",
        "epochs = 25\n",
        "lr = 1e-1\n",
        "BS = 8\n",
        "\n",
        "# lr 1e-1 works with BS of 32 epoch 25\n",
        "# lr 1e-1 works with BS of 8 epoch 25 better\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"images are being vectorized\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in covid_imgs:\n",
        "\t# use the label name from folder name\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, swap color channels, and resize it to be a fixed\n",
        "\t# 224x224 pixels while ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\t# build the feature and label vectors starting with COVID\n",
        "\tX.append(image)\n",
        "\ty.append(label)\n",
        " \n",
        "for imagePath in normal_imgs:\n",
        "\t# use the label name from folder name\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, swap color channels, and resize it to be a fixed\n",
        "\t# 224x224 pixels while ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\t# update the feature and label vectors with healthy lung x-rays\n",
        "\tX.append(image)\n",
        "\ty.append(label)\n",
        "\n",
        "\n",
        "# standardize the data to range [0, 255]\n",
        "# create numPy arrays\n",
        "X = np.array(X) / 255.0\n",
        "y = np.array(y)\n",
        "\n",
        "# One Hot Encode the data\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "random.shuffle(X)\n",
        "random.shuffle(y)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "covid_data shape: (25,)\n",
            "normal_data shape: (25,)\n",
            "images are being vectorized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkKu-HF9-t8s",
        "colab_type": "text"
      },
      "source": [
        "### Sci-Kit Learn's Train/Test Split\n",
        "\n",
        "In order to avoid overfitting of my model, which means my model would not be generalized but too specific to my data, I split the data into training and testing sets. Generally a good ratio is around 70%/30% or 80%/20%. I used the default split option in this function (which I believe is 80/20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1FaWevAXzX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split our vectors into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41uaY5oy_Fg8",
        "colab_type": "text"
      },
      "source": [
        "## Choosing the right Convolutional Neural Network\n",
        "\n",
        "I had some choices here and I was between using a VGG16 network or GoogleNet's Inception network. From what I had gathered, VGG16 was the second choice of many due to it's slow and demanding computation. I looked into the fairly new 'Inception' model from Googlenet which I learned much about and challenged myself to it's implementation for this project.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## GoogLeNet Inception Convolutional Neural Network\n",
        "Googlenet inception provides a convolutional neural network that takes an input of an image and then filters it essentially through three dimensions 1x1, 3x3, and 5x5 and a pooling layer. This reduces computational expense and avoids overfitting with a deep model. This makes your Convolutional Neural Network ‘wider’ as these operations are being performed on the same layers, and not ‘deeper’ which would have more layers for the input data vectors to pass through.\n",
        "\n",
        "In other words, if we had a network that was supposed to identify whether the picture consisted of a dog or a cat, this type of neural network would “look at the picture from different angles” in order to decide, just like a human might look at a piece of art or photo to identify what it consisted of. Why? Because every picture of a dog or a cat is not quite set up the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HxK4U0VGT4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "672da441-e32a-444a-92b3-80ddec990af5"
      },
      "source": [
        "# GooGlenet Naive Inception CNN model\n",
        "\n",
        "shapex = 224\n",
        "shapey = 224\n",
        "n_rows,n_cols,n_dims = X_train.shape[1:]\n",
        "# in_shape = (n_rows, n_cols, n_dims)\n",
        "nClasses = 2\n",
        "\n",
        "input_vec = Input(shape=(shapex, shapey, 3))\n",
        "\n",
        "hidden_layer_1 = Conv2D(10, (1,1), padding='same', activation='relu')(input_vec)\n",
        "hidden_layer_1 = Conv2D(10, (3,3), padding='same', activation='relu')(hidden_layer_1)\n",
        "\n",
        "hidden_layer_2 = Conv2D(10, (1,1), padding='same', activation='relu')(input_vec)\n",
        "hidden_layer_2 = Conv2D(10, (5,5), padding='same', activation='relu')(hidden_layer_2)\n",
        "\n",
        "hidden_layer_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_vec)\n",
        "hidden_layer_3 = Conv2D(10, (1,1), padding='same', activation='relu')(hidden_layer_3)\n",
        "\n",
        "combined_layers = keras.layers.concatenate([hidden_layer_1, hidden_layer_2, hidden_layer_3], axis = 3)\n",
        "\n",
        "flattener = Flatten()(combined_layers)\n",
        "\n",
        "dense_1 = Dense(10, activation='relu')(flattener)\n",
        "dense_2 = Dense(5, activation='relu')(dense_1)\n",
        "dense_3 = Dense(2, activation='relu')(dense_2)\n",
        "output = Dense(nClasses, activation='softmax')(dense_3)\n",
        "\n",
        "model = Model([input_vec], output)\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "fitted_model = model.fit(X_train, y_train, epochs=epochs, batch_size=BS, validation_data=(X_test, y_test))\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "# make predictions on the testing set\n",
        "print(\"Evaluating the Convoluted Neural Network. Please Wait.\")\n",
        "y_pred = model.predict(X_test, batch_size=BS)\n",
        " # # for each image in the testing set we need to find the index of the\n",
        "# # label with corresponding largest predicted probability\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
        "total = sum(sum(matrix))\n",
        "accuracy = (matrix[0, 0] + matrix[1, 1]) / total\n",
        "sensitivity = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
        "specificity = matrix[1, 1] / (matrix[1, 0] + matrix[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(matrix)\n",
        "print(\"acc: {:.4f}\".format(accuracy))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 37 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 2.2792 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2.1662 - acc: 0.8649 - val_loss: 1.2331 - val_acc: 0.9231\n",
            "Evaluating the Convoluted Neural Network. Please Wait.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.92      1.00      0.96        12\n",
            "     healthy       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.92        13\n",
            "   macro avg       0.46      0.50      0.48        13\n",
            "weighted avg       0.85      0.92      0.89        13\n",
            "\n",
            "[[12  0]\n",
            " [ 1  0]]\n",
            "acc: 0.9231\n",
            "sensitivity: 1.0000\n",
            "specificity: 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3fBV2-e5JRK",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "For the amount of data that I had I'd say the network runs fairly well. Through the countless iterations I've run with it, I seemed to get overall validation accuracy score of around 75-92%. Of course, this is hard to guarantee because of the size of the data that is being used, but definitely hopeful for the future.\n",
        "\n",
        "The confusion matrix above will outline how many predictions were false-positive, true-positive, false-negative, and true-negative. To analyze this performance metric, think this way --> You generally want the majority of your predictions to fall along the diagonal (which means your model predicted correctly), but in the cases it doesn't predict correctly, you want less to be false-positive. To explain this further, you would not want to go to the doctor and they tell you you aren't sick, when you really are. It would be less risky to be told you are sick when you actually aren't.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "***I encourage you if you have any interest to check out the current COVID-19 Research challenge that Kaggle is holding. \n",
        "\n",
        "-->https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge\n",
        "\n",
        "I treated this project as a learning process, and while making my own decisions about what to implement ultimately, I did find the following articles to be very educational and guide me in the right directions.\n",
        "\n",
        "\n",
        "-->https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/\n",
        "\n",
        "Info on Googlenet Inception CNN\n",
        "-->https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
        "\n",
        "Information on VGG16 CNN\n",
        "-->https://neurohive.io/en/popular-networks/vgg16/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
